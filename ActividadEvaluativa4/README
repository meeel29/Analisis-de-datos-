## üìò An√°lisis de Datos ‚Äì Modelos de Machine Learning

Subimos los notebooks desarrollados para el an√°lisis, preprocesamiento y experimentaci√≥n con distintos modelos de Machine Learning supervisado y no supervisado, aplicados a dos tipos de problemas:

- Predicci√≥n del rendimiento acad√©mico de estudiantes.

- Clasificaci√≥n de sentimiento en texto (rese√±as).

Adem√°s incluimos t√©cnicas de reducci√≥n de dimensionalidad, vectorizaci√≥n de texto, visualizaciones, m√©tricas, y la comparaci√≥n detallada de tres m√©todos de ML.
---
## üìÇ Contenido de los notebooks
1. Predicci√≥n del rendimiento acad√©mico ‚Äì Student Performance (Math)
‚úî Descripci√≥n del problema

Se busca predecir la variable GradeClass (alto / medio / bajo) derivada de la nota final G3, usando caracter√≠sticas acad√©micas, personales y contextuales de estudiantes.

‚úî Preprocesamiento realizado

Imputaci√≥n de valores faltantes (mediana/moda).

Codificaci√≥n One-Hot para variables categ√≥ricas.

Estandarizaci√≥n de variables num√©ricas.

Divisi√≥n train/test 75/25, estratificada.

‚úî Modelos evaluados

Regresi√≥n Log√≠stica

√Årboles de Decisi√≥n

Random Forest

‚úî Visualizaciones

Histogramas y distribuci√≥n de notas.

Matriz de correlaci√≥n.

Importancia de caracter√≠sticas seg√∫n los modelos.

2. Clasificaci√≥n de Sentimiento en Texto

(Basado en rese√±as positivas/negativas)

‚úî Procesamiento de texto

Limpieza: min√∫sculas, eliminaci√≥n de puntuaci√≥n, stopwords y tokens ruidosos.

Tokenizaci√≥n y vectorizaci√≥n usando TF-IDF (m√°x. features = 5000).

Se usaron unigramas (palabras individuales).

Los bigramas no se usaron debido al alto costo computacional y la dispersi√≥n de la matriz.

‚úî Modelos comparados

Naive Bayes

Regresi√≥n Log√≠stica

SVM (LinearSVC)

‚úî Resultados principales

SVM tuvo la mejor precisi√≥n y generalizaci√≥n.

Regresi√≥n Log√≠stica tambi√©n funcion√≥ muy bien en texto con alta dimensionalidad.

Naive Bayes fue el m√°s r√°pido, pero el que menor rendimiento obtuvo.

‚úî Nubes de palabras

Se generaron wordclouds para rese√±as positivas y negativas.
Se resalta que algunas palabras aparecen en ambos grupos por:

Rese√±as mixtas

Palabras neutrales (producto, libro‚Ä¶)

Ruido del dataset

Eliminaci√≥n de contexto al limpiar el texto

‚úî Extracci√≥n de palabras m√°s importantes

Se listaron las top 20 palabras positivas y negativas seg√∫n los coeficientes de Regresi√≥n Log√≠stica.

3. Reducci√≥n de Dimensionalidad

Se aplicaron t√©cnicas para visualizar los embeddings de texto generado por TF-IDF:

‚úî PCA (Componentes Principales)

Reduce miles de dimensiones a 2.

Se observ√≥ mezcla entre clases, algo normal en texto lineal con TF-IDF.

‚úî t-SNE

Captura relaciones no lineales.

Form√≥ grupos m√°s diferenciados que PCA, aunque con cierta superposici√≥n.

‚úî Wordclouds + Distribuciones

Ayudaron a interpretar patrones de lenguaje en ambos tipos de rese√±as.
---
## üìä M√©tricas utilizadas

Accuracy

F1-Score

Precision / Recall

Matriz de confusi√≥n

Para clustering (cuando aplicaba):

Silhouette score

---
## üìù Conclusiones

La calidad del preprocesamiento (limpieza, codificaci√≥n y vectorizaci√≥n) afecta directamente el desempe√±o de los modelos.

Los modelos lineales (SVM, Regresi√≥n Log√≠stica) son especialmente efectivos en datos de alta dimensionalidad generados por TF-IDF.

En Student Performance, las variables G1 y G2 son altamente predictivas de la nota final.

PCA muestra mezcla natural entre clases en texto, mientras que t-SNE ofrece una separaci√≥n m√°s clara y √∫til para an√°lisis exploratorio.

El proyecto demuestra un flujo completo de ML: EDA ‚Üí Limpieza ‚Üí Vectorizaci√≥n ‚Üí Modelado ‚Üí M√©tricas ‚Üí Reducci√≥n ‚Üí Interpretaci√≥n.
---

## üë• Integrantes

- Sara Estefania Bermudez Alvarez 
- Melissa Mahecha Garcia 
- Camilo V√°squez Suarez

---
## Video

El video correspondiente a los dos ejercicios se encuentra en la ruta: https://youtu.be/OMHdATuk4zQ