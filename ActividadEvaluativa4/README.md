## üìò An√°lisis de Datos ‚Äì Modelos de Machine Learning

Subimos los notebooks desarrollados para el an√°lisis, preprocesamiento y experimentaci√≥n con distintos modelos de Machine Learning supervisado y no supervisado, aplicados a dos tipos de problemas:

- Predicci√≥n del rendimiento acad√©mico de estudiantes.
- Clasificaci√≥n de sentimiento en texto (rese√±as).

Adem√°s incluimos t√©cnicas de reducci√≥n de dimensionalidad, vectorizaci√≥n de texto, visualizaciones, m√©tricas, y la comparaci√≥n detallada de tres m√©todos de ML.

---

## üìÇ Contenido de los notebooks

---

### 1. Predicci√≥n del rendimiento acad√©mico ‚Äì Student Performance (Math)

#### ‚úî Descripci√≥n del problema
Se busca predecir la variable **GradeClass** (alto / medio / bajo) derivada de la nota final G3, usando caracter√≠sticas acad√©micas, personales y contextuales de estudiantes.

#### ‚úî Preprocesamiento realizado
- Imputaci√≥n de valores faltantes (mediana/moda).
- Codificaci√≥n One-Hot para variables categ√≥ricas.
- Estandarizaci√≥n de variables num√©ricas.
- Divisi√≥n **train/test 75/25**, estratificada.

#### ‚úî Modelos evaluados
- Regresi√≥n Log√≠stica  
- √Årboles de Decisi√≥n  
- Random Forest  

#### ‚úî Visualizaciones
- Histogramas y distribuci√≥n de notas.
- Matriz de correlaci√≥n.
- Importancia de caracter√≠sticas seg√∫n los modelos.

---

### 2. Clasificaci√≥n de Sentimiento en Texto  
*(Basado en rese√±as positivas/negativas)*

#### ‚úî Procesamiento de texto
- Limpieza: min√∫sculas, eliminaci√≥n de puntuaci√≥n, stopwords y tokens ruidosos.
- Tokenizaci√≥n y vectorizaci√≥n usando **TF-IDF** (m√°x. features = 5000).
- Se usaron **unigramas**.
- Los **bigramas NO se usaron** por costo computacional y dispersi√≥n.

#### ‚úî Modelos comparados
- Naive Bayes  
- Regresi√≥n Log√≠stica  
- SVM (LinearSVC)

#### ‚úî Resultados principales
- **SVM** tuvo la mejor precisi√≥n y generalizaci√≥n.
- Regresi√≥n Log√≠stica tambi√©n funcion√≥ muy bien en texto de alta dimensionalidad.
- Naive Bayes fue el m√°s r√°pido, pero con menor rendimiento.

#### ‚úî Nubes de palabras
Se generaron wordclouds para rese√±as positivas y negativas.  
Se encontr√≥ que algunas palabras aparecen en ambos grupos debido a:
- Rese√±as mixtas
- Palabras neutrales (producto, libro‚Ä¶)
- Ruido del dataset
- Eliminaci√≥n del contexto en la limpieza

#### ‚úî Extracci√≥n de palabras m√°s importantes
Se listaron las **top 20** palabras positivas y negativas seg√∫n los coeficientes de Regresi√≥n Log√≠stica.

---

### 3. Reducci√≥n de Dimensionalidad

#### ‚úî PCA (Componentes Principales)
- Reduce miles de dimensiones a 2.
- Se observ√≥ mezcla entre clases (normal en texto vectorizado).

#### ‚úî t-SNE
- Captura relaciones no lineales.
- Form√≥ grupos mejor separados que PCA.

#### ‚úî Wordclouds + Distribuciones
- Ayudaron a interpretar patrones en ambos tipos de rese√±as.

---

## üìä M√©tricas utilizadas
- Accuracy  
- F1-Score  
- Precision / Recall  
- Matriz de confusi√≥n  
- (Para clustering) Silhouette score

---

## üìù Conclusiones
- La calidad del **preprocesamiento** afecta directamente el desempe√±o de los modelos.
- Los modelos lineales (SVM, Regresi√≥n Log√≠stica) funcionan muy bien con TF-IDF.
- En Student Performance, **G1 y G2** son altamente predictivas de G3.
- PCA muestra mezcla entre clases; **t-SNE** ofrece mejor separaci√≥n visual.
- El proyecto demuestra un flujo completo:  
  **EDA ‚Üí Limpieza ‚Üí Vectorizaci√≥n ‚Üí Modelado ‚Üí M√©tricas ‚Üí Reducci√≥n ‚Üí Interpretaci√≥n.**

---

## üë• Integrantes
- Sara Estefania Berm√∫dez √Ålvarez  
- Melissa Mahecha Garc√≠a  
- Camilo V√°squez Su√°rez  

---

## üé¨ Video
El video correspondiente a los ejercicios se encuentra en:  
https://youtu.be/OMHdATuk4zQ
